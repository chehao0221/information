import feedparser
import requests
import os
import urllib.parse
from datetime import datetime

# è®€å–ä¸¦æ¸…ç† Secret
WEBHOOK = os.environ.get("NEWS_WEBHOOK_URL", "").strip()

def get_news(query, lang='zh-TW', region='TW'):
    safe_query = urllib.parse.quote(query)
    url = f"https://news.google.com/rss/search?q={safe_query}&hl={lang}&gl={region}&ceid={region}:{lang}"
    feed = feedparser.parse(url)
    # é™åˆ¶åªå–å‰ 2 å‰‡ï¼Œç¢ºä¿è¨Šæ¯ä¸æœƒéé•·è¢« Discord é˜»æ“‹
    return [{"title": entry.title, "link": entry.link} for entry in feed.entries[:2]] if feed.entries else []

def run():
    if not WEBHOOK:
        print("âŒ éŒ¯èª¤ï¼šæ‰¾ä¸åˆ° NEWS_WEBHOOK_URL")
        return

    # å®šç¾©é—œéµè¿½è¹¤æ¨™çš„
    tw_targets = {"ğŸ“ˆ å°è‚¡å¤§ç›¤": "å°è‚¡ èµ°å‹¢", "æ™¶åœ“ä»£å·¥": "å°ç©é›» 2330"}
    us_targets = {"ğŸ¦… è¯æº–æœƒè¶¨å‹¢": "Fed CPI", "ğŸ’» ç¾è‚¡ç§‘æŠ€": "NVIDIA Apple"}

    now = datetime.now().strftime("%Y-%m-%d %H:%M")
    msg = f"ğŸ—ï¸ **å°ç¾è‚¡ç›¤å‰æƒ…å ±** ({now})\nâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n"

    # å°è‚¡æ‘˜è¦
    for label, query in tw_targets.items():
        news = get_news(query)
        msg += f"**{label}**\n"
        for n in news:
            msg += f"ğŸ”¹ {n['title']}\n<{n['link']}>\n"
    
    msg += "\n"

    # ç¾è‚¡æ‘˜è¦
    for label, query in us_targets.items():
        news = get_news(query, lang='zh-TW', region='US')
        msg += f"**{label}**\n"
        for n in news:
            msg += f"ğŸ”¸ {n['title']}\n<{n['link']}>\n"

    msg += "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\nğŸ’¡ *AI è‡ªå‹•å½™æ•´ï¼ŒæŠ•è³‡è«‹ç¨ç«‹è©•ä¼°ã€‚*"

    # ç™¼é€æ­£å¼æ–°è
    res = requests.post(WEBHOOK, json={"content": msg}, timeout=15)
    print(f"ğŸ“¡ æœ€çµ‚ç™¼é€ç‹€æ…‹: {res.status_code}")

if __name__ == "__main__":
    run()
