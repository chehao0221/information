# -*- coding: utf-8 -*-
"""
å°è‚¡ / ç¾è‚¡ / Crypto å¸‚å ´å¿«è¨Šï¼ˆDiscord Webhookï¼‰

é¡¯ç¤ºæ–¹å¼ï¼šä¸€å‰‡æ–°èä¸€å€‹ embedï¼ˆå¡ç‰‡ï¼‰ï¼Œä¸¦é™„å¸‚å ´å€å¡Šæ¨™é¡Œå¡ã€‚
- å°è‚¡ï¼šè—è‰²
- ç¾è‚¡ï¼šç´…è‰²
- Cryptoï¼šé»ƒè‰²
"""
from __future__ import annotations

import datetime as _dt
import os
import re
from typing import Dict, List, Optional, Tuple

import feedparser
import requests
import yfinance as yf


# =========================
# è¨­å®š
# =========================
DISCORD_WEBHOOK_URL = os.getenv("NEWS_WEBHOOK_URL", "").strip()
CACHE_FILE = "data/sent_news.txt"
HTTP_TIMEOUT = 15

# Discord limits
MAX_EMBEDS_PER_MESSAGE = 10
MAX_TITLE_LEN = 256
MAX_FIELD_VALUE_LEN = 1024
MAX_DESC_LEN = 4096

# Colors (decimal)
COLOR_TW = 0x3498DB   # blue
COLOR_US = 0xE74C3C   # red
COLOR_CRYPTO = 0xF1C40F  # yellow

# Google News RSS endpoint
GOOGLE_NEWS_RSS = "https://news.google.com/rss/search"


# =========================
# å°å·¥å…·
# =========================
def _ensure_data_dir() -> None:
    os.makedirs(os.path.dirname(CACHE_FILE), exist_ok=True)


def _load_sent_keys() -> set:
    if not os.path.exists(CACHE_FILE):
        return set()
    with open(CACHE_FILE, "r", encoding="utf-8") as f:
        return set([line.strip() for line in f if line.strip()])


def _append_sent_keys(keys: List[str]) -> None:
    if not keys:
        return
    with open(CACHE_FILE, "a", encoding="utf-8") as f:
        for k in keys:
            f.write(k + "\n")


def _truncate(s: str, n: int) -> str:
    s = s or ""
    return s if len(s) <= n else (s[: max(0, n - 1)] + "â€¦")


def _fmt_taipei_now() -> str:
    # GitHub Actions é è¨­ UTCï¼Œé€™è£¡ç”¨ UTC+8 é¡¯ç¤ºï¼ˆå°åŒ—ï¼‰
    now_utc = _dt.datetime.utcnow().replace(tzinfo=_dt.timezone.utc)
    now_tw = now_utc.astimezone(_dt.timezone(_dt.timedelta(hours=8)))
    return now_tw.strftime("%Y-%m-%d %H:%M")


def _safe_field(name: str, value: str, inline: bool = False) -> Dict:
    name = _truncate(name, MAX_TITLE_LEN)
    value = value if value else "â€”"
    value = _truncate(value, MAX_FIELD_VALUE_LEN)
    return {"name": name, "value": value, "inline": inline}


def _http_get(url: str, params: Optional[dict] = None) -> str:
    r = requests.get(url, params=params, timeout=HTTP_TIMEOUT, headers={"User-Agent": "Mozilla/5.0"})
    r.raise_for_status()
    return r.text


def _fetch_google_news(query: str, lang: str = "zh-TW", region: str = "TW") -> List[dict]:
    """
    å›å‚³ list[{"title": str, "publisher": str, "link": str, "published": str}]
    """
    params = {"q": query, "hl": lang, "gl": region, "ceid": f"{region}:{lang}"}
    rss_text = _http_get(GOOGLE_NEWS_RSS, params=params)
    feed = feedparser.parse(rss_text)

    posts: List[dict] = []
    for e in feed.entries[:50]:
        raw_title = (e.get("title") or "").strip()
        link = (e.get("link") or "").strip()
        published = (e.get("published") or e.get("updated") or "").strip()

        # Google News title å¸¸æ˜¯ "headline - Publisher"
        headline, publisher = _split_headline_publisher(raw_title)
        posts.append(
            {
                "headline": headline,
                "publisher": publisher,
                "title": raw_title,
                "link": link,
                "published": published,
            }
        )
    return posts


def _split_headline_publisher(raw_title: str) -> Tuple[str, str]:
    # æœ€å¾Œä¸€æ®µç•¶ publisherï¼ˆç›¡é‡è²¼è¿‘ä½ èˆŠç‰ˆï¼‰
    parts = [p.strip() for p in raw_title.split(" - ") if p.strip()]
    if len(parts) >= 2:
        return " - ".join(parts[:-1]).strip(), parts[-1].strip()
    return raw_title.strip(), ""


def _make_dedupe_key(post: dict) -> str:
    # ä»¥ link ç‚ºä¸»ï¼Œé¿å…æ¨™é¡Œå¾®èª¿é€ æˆé‡ç™¼
    return post.get("link") or post.get("title") or ""


def _dedupe(posts: List[dict], sent: set) -> Tuple[List[dict], List[str]]:
    new_posts: List[dict] = []
    new_keys: List[str] = []
    for p in posts:
        k = _make_dedupe_key(p)
        if not k or k in sent:
            continue
        new_posts.append(p)
        new_keys.append(k)
    return new_posts, new_keys


_POS_KW = ["å¤§æ¼²", "ä¸Šæ¼²", "å¼·å½ˆ", "å‰µé«˜", "åˆ©å¤š", "çœ‹å¥½", "è²·ç›¤", "çºŒå¼·", "åå½ˆ", "ä¸Šæ”»", "é£†", "å™´"]
_NEG_KW = ["å¤§è·Œ", "ä¸‹è·Œ", "å´©", "é‡æŒ«", "åˆ©ç©º", "è­¦è¨Š", "ææ…Œ", "å›æª”", "ä¸‹ä¿®", "èµ°å¼±", "æš´è·Œ"]


def _judge_from_headline(headline: str) -> Tuple[str, str]:
    """
    å›å‚³ (å¸‚å ´åˆ¤æ–·, åˆ©å¤š/åˆ©ç©º/ä¸­æ€§)
    """
    h = headline or ""
    if any(k in h for k in _POS_KW):
        return "åå¤š", "åˆ©å¤š"
    if any(k in h for k in _NEG_KW):
        return "åç©º", "åˆ©ç©º"
    return "ä¸­æ€§", "ä¸­æ€§"


_TW_TICKER_RE = re.compile(r"\b(\d{4}\.TW)\b")
_US_TICKER_RE = re.compile(r"\b([A-Z]{1,5})\b")


def _extract_ticker(headline: str, market: str) -> Optional[str]:
    if market == "TW":
        m = _TW_TICKER_RE.search(headline or "")
        return m.group(1) if m else None
    if market == "US":
        # é¿å…æŠ“åˆ°å¤ªå¤šç„¡é—œå¤§å¯«è©ï¼šåªåœ¨æœ‰ã€Œè‚¡ã€æˆ–ã€ŒNYSE/Nasdaqã€ç­‰ç·šç´¢æ™‚æ‰å˜—è©¦
        h = headline or ""
        if not any(x in h for x in ["è‚¡", "NYSE", "Nasdaq", "NASDAQ", "ç¾è‚¡", "ç¾åœ‹"]):
            return None
        # å–ç¬¬ä¸€å€‹è¼ƒåƒ ticker çš„å¤§å¯«å­—ä¸²ï¼ˆç°¡å–®ä¿å®ˆï¼‰
        for m in _US_TICKER_RE.finditer(h):
            t = m.group(1)
            if t in {"OR", "AND", "THE", "FED", "BTC", "ETH"}:
                continue
            if 1 <= len(t) <= 5:
                return t
        return None
    if market == "CRYPTO":
        if "ETH" in (headline or "").upper() or "ä»¥å¤ª" in (headline or ""):
            return "ETH-USD"
        if "BTC" in (headline or "").upper() or "æ¯”ç‰¹" in (headline or ""):
            return "BTC-USD"
        return None
    return None


def _get_quote(ticker: str) -> Optional[str]:
    """
    å›å‚³ "1585.00 (+2.26%)" é¡å‹æ–‡å­—ï¼ˆå–æœ€è¿‘ä¸€ç­† close & å‰ä¸€ç­† closeï¼‰
    """
    try:
        t = yf.Ticker(ticker)
        hist = t.history(period="5d", interval="1d")
        if hist is None or hist.empty or len(hist["Close"]) < 2:
            return None
        closes = hist["Close"].dropna()
        if len(closes) < 2:
            return None
        last = float(closes.iloc[-1])
        prev = float(closes.iloc[-2])
        chg = last - prev
        pct = (chg / prev) * 100 if prev else 0.0
        sign = "+" if chg >= 0 else ""
        return f"{last:.2f} ({sign}{pct:.2f}%)"
    except Exception:
        return None


def _get_index_line(market: str) -> Optional[str]:
    """
    å°è‚¡ï¼šåŠ æ¬ŠæŒ‡æ•¸ ^TWII
    ç¾è‚¡ï¼šé‚£æ–¯é”å…‹ ^IXIC
    Cryptoï¼šBTC-USD
    """
    if market == "TW":
        name, ticker = "åŠ æ¬ŠæŒ‡æ•¸", "^TWII"
    elif market == "US":
        name, ticker = "é‚£æ–¯é”å…‹", "^IXIC"
    else:
        name, ticker = "æ¯”ç‰¹å¹£(BTC)", "BTC-USD"

    q = _get_quote(ticker)
    if not q:
        return None
    return f"{name}: {q}"


def _build_header_embed(market_name: str, market: str) -> dict:
    now = _fmt_taipei_now()
    idx = _get_index_line(market)
    title = f"{market_name}å¸‚å ´å¿«è¨Š"
    desc_lines = [f"ğŸ“… {now}"]
    if idx:
        desc_lines.append(f"ğŸ“Š {idx}")
    description = "\n".join(desc_lines)
    color = COLOR_TW if market == "TW" else COLOR_US if market == "US" else COLOR_CRYPTO
    return {
        "title": _truncate(title, MAX_TITLE_LEN),
        "description": _truncate(description, MAX_DESC_LEN),
        "color": color,
    }


def _build_news_embed(post: dict, market: str) -> dict:
    headline = post.get("headline") or post.get("title") or ""
    publisher = post.get("publisher") or ""
    link = post.get("link") or ""
    published = post.get("published") or ""

    judgement, sentiment = _judge_from_headline(headline)
    ticker = _extract_ticker(headline, market)
    quote = _get_quote(ticker) if ticker else None

    color = COLOR_TW if market == "TW" else COLOR_US if market == "US" else COLOR_CRYPTO

    fields = []
    fields.append(_safe_field("âš–ï¸ å¸‚å ´åˆ¤æ–·", judgement, inline=True))
    fields.append(_safe_field("ğŸ“ˆ åˆ©å¤š/åˆ©ç©º", sentiment, inline=True))
    if quote:
        fields.append(_safe_field("ğŸ’¹ å³æ™‚åƒ¹æ ¼", quote, inline=True))
    if published:
        # ç›¡é‡è²¼è¿‘ä½ èˆŠç‰ˆã€Œç™¼å¸ƒæ™‚é–“ã€å‘ˆç¾ï¼ˆå–å­—ä¸²ï¼Œä¸ç¡¬è½‰æ™‚å€ï¼‰
        fields.append(_safe_field("ğŸ•’ ç™¼å¸ƒæ™‚é–“", published, inline=False))
    if publisher:
        fields.append(_safe_field("ğŸ“° æ–°èä¾†æº", publisher, inline=True))

    embed = {
        "title": _truncate(headline, MAX_TITLE_LEN),
        "url": link,  # é»æ¨™é¡Œå³å¯é–‹é€£çµï¼ˆä¸æœƒé¡å¤– unfurlï¼‰
        "color": color,
        "fields": fields,
        "footer": {"text": "Smart News Radar System"},
    }

    return embed


def _post_webhook(embeds: List[dict]) -> None:
    if not DISCORD_WEBHOOK_URL:
        print("âš ï¸ NEWS_WEBHOOK_URL æœªè¨­å®šï¼Œè·³éæ¨æ’­ã€‚")
        return
    payload = {
        "embeds": embeds,
    }
    r = requests.post(DISCORD_WEBHOOK_URL, json=payload, timeout=HTTP_TIMEOUT)
    if r.status_code >= 300:
        raise RuntimeError(f"Discord webhook failed: {r.status_code} {r.text[:800]}")


def _send_market_block(market: str, market_name: str, posts: List[dict]) -> None:
    if not posts:
        return

    header = _build_header_embed(market_name, market)
    news_embeds = [_build_news_embed(p, market) for p in posts]

    # Discord ä¸€æ¬¡æœ€å¤š 10 å€‹ embedsï¼šheader + 9 news
    i = 0
    first = True
    while i < len(news_embeds):
        batch_news = news_embeds[i : i + (MAX_EMBEDS_PER_MESSAGE - 1)]
        embeds = []
        if first:
            embeds.append(header)
            first = False
        else:
            # çºŒé ä¹ŸåŠ ä¸€å€‹ç°¡çŸ­ headerï¼Œæ–¹ä¾¿é–±è®€ï¼ˆä½†ä¿æŒå¾ˆçŸ­ï¼‰
            cont_header = dict(header)
            cont_header["title"] = _truncate(f"{market_name}å¸‚å ´å¿«è¨Šï¼ˆçºŒï¼‰", MAX_TITLE_LEN)
            embeds.append(cont_header)

        embeds.extend(batch_news)
        _post_webhook(embeds)
        i += (MAX_EMBEDS_PER_MESSAGE - 1)


def run_push() -> None:
    _ensure_data_dir()
    sent = _load_sent_keys()

    # ä¸»è¦é—œéµå­—ï¼ˆç¶­æŒä½ åŸæœ¬æ–¹å‘ï¼šå°è‚¡ / ç¾è‚¡ / Cryptoï¼‰
    tw_query = "å°è‚¡ OR å°ç£ è‚¡å¸‚ OR åŠ æ¬ŠæŒ‡æ•¸ OR å°æŒ‡æœŸ OR å°ç©é›»"
    us_query = "ç¾è‚¡ OR ç¾åœ‹ è‚¡å¸‚ OR é“ç“Š OR é‚£æ–¯é”å…‹ OR æ¨™æ™®500 OR è¯æº–æœƒ OR Fed"
    crypto_query = "æ¯”ç‰¹å¹£ OR ä»¥å¤ªåŠ OR åŠ å¯†è²¨å¹£ OR Bitcoin OR Ethereum"

    tw_posts, tw_keys = _dedupe(_fetch_google_news(tw_query), sent)
    us_posts, us_keys = _dedupe(_fetch_google_news(us_query), sent)
    crypto_posts, crypto_keys = _dedupe(_fetch_google_news(crypto_query), sent)

    any_sent_keys: List[str] = []

    if tw_posts:
        _send_market_block("TW", "å°è‚¡", tw_posts)
        any_sent_keys += tw_keys
    if us_posts:
        _send_market_block("US", "ç¾è‚¡", us_posts)
        any_sent_keys += us_keys
    if crypto_posts:
        _send_market_block("CRYPTO", "Crypto", crypto_posts)
        any_sent_keys += crypto_keys

    if any_sent_keys:
        _append_sent_keys(any_sent_keys)
        print(f"âœ… Sent {len(any_sent_keys)} new items.")
    else:
        print("â„¹ï¸ No new items.")


if __name__ == "__main__":
    run_push()
