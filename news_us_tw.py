import yfinance as yf
import pandas as pd
import numpy as np
import requests
import datetime
import os
import feedparser
import urllib.parse
from xgboost import XGBRegressor
import warnings

warnings.filterwarnings("ignore")

DISCORD_WEBHOOK_URL = os.getenv("NEWS_WEBHOOK_URL")

def get_live_news(query):
    try:
        safe_query = urllib.parse.quote(query)
        url = f"https://news.google.com/rss/search?q={safe_query}&hl=zh-TW&gl=TW&ceid=TW:zh-TW"
        feed = feedparser.parse(url)
        news_items = []
        for entry in feed.entries[:2]:
            clean_title = entry.title.split(" - ")[0]
            news_items.append(f"  - {clean_title}\n    <{entry.link}>")
        return "\n".join(news_items) if news_items else "  (ç„¡è¿‘æœŸç›¸é—œæ–°è)"
    except:
        return "  (æ–°èæŠ“å–å¤±æ•—)"

def compute_features(df):
    df = df.copy()
    # ç¢ºä¿æ¬„ä½åç¨±æ­£ç¢º
    df["mom20"] = df["Close"].pct_change(20)
    df["mom60"] = df["Close"].pct_change(60)
    delta = df["Close"].diff()
    up = delta.clip(lower=0).rolling(14).mean()
    down = (-delta.clip(upper=0)).rolling(14).mean()
    df["rsi"] = 100 - (100 / (1 + up / (down + 1e-9)))
    df["vol_ratio"] = df["Volume"] / (df["Volume"].rolling(20).mean() + 1e-9)
    df["volatility"] = df["Close"].pct_change().rolling(20).std()
    return df

def run():
    if not DISCORD_WEBHOOK_URL: return
    
    must_watch = ["2330.TW", "2317.TW", "0050.TW", "AAPL", "NVDA"]
    tz = datetime.timezone(datetime.timedelta(hours=8))
    today = datetime.datetime.now(tz).strftime("%Y-%m-%d %H:%M")
    
    # ç©©å®šæŠ“å–æ•¸æ“š
    report = f"ğŸ¤– **AI æŠ•è³‡æƒ…å ±ç«™** ({today})\nâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n\n"

    for sym in must_watch:
        try:
            # é€ä¸€æŠ“å–æ¨™çš„ï¼Œé¿å… MultiIndex é€ æˆè§£æéŒ¯èª¤
            ticker = yf.Ticker(sym)
            df = ticker.history(period="2y")
            
            if df.empty:
                report += f"âš ï¸ **{sym}** | ç„¡æ³•ç²å–è¡Œæƒ…æ•¸æ“š\n\n"
                continue

            # æŠ“å–æ–°è
            news_query = sym.split('.')[0]
            news_content = get_live_news(news_query)
            
            # AI é æ¸¬é‚è¼¯
            ai_info = "(è¨ˆç®—ä¸­)"
            if len(df) > 60:
                try:
                    df_feat = compute_features(df)
                    df_feat["target"] = df_feat["Close"].shift(-5) / df_feat["Close"] - 1
                    features = ["mom20", "mom60", "rsi", "vol_ratio", "volatility"]
                    train_df = df_feat.dropna(subset=features + ["target"])
                    
                    model = XGBRegressor(n_estimators=50, max_depth=3)
                    model.fit(train_df[features], train_df["target"])
                    pred = float(model.predict(df_feat[features].iloc[-1:])[0])
                    
                    status = "ğŸš€" if pred > 0.01 else "ğŸ“ˆ" if pred > 0 else "â˜ï¸"
                    ai_info = f"{status} é ä¼°: `{pred:+.2%}`"
                except:
                    ai_info = "ğŸ“ˆ åˆ†æå®Œç•¢"

            curr_price = float(df['Close'].iloc[-1])
            report += f"**{sym}** | {ai_info}\n"
            report += f"  - ç¾åƒ¹: {curr_price:.2f}\n"
            report += f"{news_content}\n\n"
            
        except Exception as e:
            print(f"Error processing {sym}: {e}")
            report += f"âš ï¸ **{sym}** | æ•¸æ“šè§£æç•°å¸¸\n\n"

    report += "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
    requests.post(DISCORD_WEBHOOK_URL, json={"content": report})

if __name__ == "__main__":
    run()
