import datetime
import os
import re
import urllib.parse
from typing import Dict, List

import feedparser
import requests


# =========================
# è¨­å®š
# =========================
DISCORD_WEBHOOK_URL = os.getenv("NEWS_WEBHOOK_URL", "").strip()
CACHE_FILE = "data/sent_news.txt"

# Google News RSS
# èªç³»ï¼šç¹ä¸­ï¼ˆå°ç£ï¼‰
GOOGLE_NEWS_RSS = "https://news.google.com/rss/search?q={query}&hl=zh-TW&gl=TW&ceid=TW:zh-Hant"

# æœ€å¤šæ¨æ’­å¹¾å‰‡ï¼ˆæ¯å€‹åˆ†é¡ï¼‰
MAX_ITEMS_PER_SECTION = 6
# å¿«å–æœ€å¤šä¿ç•™å¹¾ç­†ï¼ˆé¿å… repo è¶Šä¾†è¶Šå¤§ï¼‰
CACHE_KEEP_LIMIT = 300

# Requests timeout
HTTP_TIMEOUT = 12


def _ensure_data_dir() -> None:
    if not os.path.exists("data"):
        os.makedirs("data", exist_ok=True)


def _normalize_title(title: str) -> str:
    # ç°¡å–®æ­£è¦åŒ–ï¼šå»ç©ºç™½ã€é™å™ªç¬¦è™Ÿã€è½‰å°å¯«
    t = (title or "").strip().lower()
    t = re.sub(r"\s+", " ", t)
    return t


def _load_sent_titles() -> List[str]:
    if not os.path.exists(CACHE_FILE):
        return []
    try:
        with open(CACHE_FILE, "r", encoding="utf-8") as f:
            return [line.strip() for line in f if line.strip()]
    except Exception:
        return []


def _save_sent_titles(titles: List[str]) -> None:
    _ensure_data_dir()
    # å»é‡ + é™åˆ¶é•·åº¦
    seen = set()
    cleaned: List[str] = []
    for t in titles:
        nt = _normalize_title(t)
        if not nt or nt in seen:
            continue
        seen.add(nt)
        cleaned.append(t.strip())
    cleaned = cleaned[:CACHE_KEEP_LIMIT]
    with open(CACHE_FILE, "w", encoding="utf-8") as f:
        for t in cleaned:
            f.write(f"{t}\n")


def _fetch_google_news(query: str) -> List[Dict[str, str]]:
    q = urllib.parse.quote_plus(query)
    url = GOOGLE_NEWS_RSS.format(query=q)

    feed = feedparser.parse(url)
    posts: List[Dict[str, str]] = []
    for e in (feed.entries or []):
        title = (e.get("title") or "").strip()
        link = (e.get("link") or "").strip()
        if not title or not link:
            continue
        posts.append({"title": title, "link": link})
    return posts


def _dedupe(posts: List[Dict[str, str]], sent_titles: List[str]) -> List[Dict[str, str]]:
    sent_norm = set(_normalize_title(t) for t in sent_titles)
    out: List[Dict[str, str]] = []
    for p in posts:
        nt = _normalize_title(p.get("title", ""))
        if not nt or nt in sent_norm:
            continue
        out.append(p)
    return out


def _build_section_lines(posts: List[Dict[str, str]], limit: int) -> str:
    # Discord Embed description ä¸Šé™ 4096ï¼Œä¿å®ˆæˆªæ–·
    lines: List[str] = []
    for p in posts[:limit]:
        title = p["title"]
        link = p["link"]
        lines.append(f"â€¢ [{title}]({link})")
    text = "\n".join(lines)
    return text[:3900]  # ç•™ buffer


def send_to_discord(title: str, sections: List[Dict[str, str]]) -> None:
    """
    Send to Discord via webhook.
    Discord limits (rough):
      - embed.description: 4096 chars
      - embeds per message: 10
    sections: [{"name": "å°è‚¡", "content": "..."} , ...]
    """
    if not DISCORD_WEBHOOK_URL:
        print("âš ï¸ NEWS_WEBHOOK_URL æœªè¨­å®šï¼Œè·³éæ¨æ’­ã€‚")
        return

    # Build blocks in the same display style: **å€å¡Šå** + å…§å®¹ï¼ˆå¤šè¡Œï¼‰
    blocks: List[str] = []
    for s in sections:
        name = (s.get("name") or "").strip()
        content = (s.get("content") or "").strip()
        if not content:
            continue
        if name:
            blocks.append(f"**{name}**\n{content}")
        else:
            blocks.append(content)

    combined = "\n\n".join(blocks).strip()
    if not combined:
        combined = "ï¼ˆæœ¬æ¬¡æ²’æœ‰æ–°çš„æ›´æ–°ï¼‰"

    # Split into chunks that fit embed.description
    max_desc = 3900  # leave headroom for safety
    lines = combined.splitlines()
    chunks: List[str] = []
    buf: List[str] = []
    size = 0
    for line in lines:
        # +1 for newline
        add = len(line) + (1 if buf else 0)
        if size + add > max_desc:
            chunks.append("\n".join(buf).strip())
            buf = [line]
            size = len(line)
        else:
            if buf:
                buf.append(line)
                size += len(line) + 1
            else:
                buf = [line]
                size = len(line)
    if buf:
        chunks.append("\n".join(buf).strip())

    # Discord max 10 embeds per message. If more, merge overflow into the last embed (truncate).
    if len(chunks) > 10:
        head = chunks[:9]
        tail = "\n\n".join(chunks[9:])
        tail = tail[:max_desc]
        chunks = head + [tail]

    embeds = []
    now = datetime.datetime.utcnow().replace(microsecond=0).isoformat() + "Z"
    for i, desc in enumerate(chunks):
        emb = {
            "description": desc or "ï¼ˆç©ºç™½ï¼‰",
            "timestamp": now,
        }
        if i == 0:
            emb["title"] = (title or "News")[:256]
        embeds.append(emb)

    payload = {"embeds": embeds}

    try:
        r = requests.post(DISCORD_WEBHOOK_URL, json=payload, timeout=HTTP_TIMEOUT)
    except Exception as e:
        print(f"âŒ Discord webhook request error: {e}")
        return

    if r.status_code >= 300:
        # Don't hard-fail the whole workflow; log details for debugging.
        print(f"âŒ Discord webhook failed: {r.status_code} {r.text[:500]}")
        return

def run_push(label: str) -> None:
    """
    ä»¥ã€Œå°è‚¡ / ç¾è‚¡ / Cryptoã€ç‚ºä¸»ï¼Œæ¯æ¬¡æ¨æ’­å›ºå®šä¸‰æ®µï¼ˆå…§å®¹ä¸è¶³å°±ç•¥éï¼‰ã€‚
    """
    _ensure_data_dir()
    sent_titles = _load_sent_titles()

    # ä¸»è¦é—œéµå­—ï¼ˆä½ å¯ä»¥ä¹‹å¾Œå†è‡ªè¡Œå¾®èª¿ï¼‰
    tw_query = "å°è‚¡ OR å°ç£ è‚¡å¸‚ OR åŠ æ¬ŠæŒ‡æ•¸ OR å°æŒ‡æœŸ OR å°ç©é›»"
    us_query = "ç¾è‚¡ OR ç¾åœ‹ è‚¡å¸‚ OR é“ç“Š OR é‚£æ–¯é”å…‹ OR æ¨™æ™®500 OR è¯æº–æœƒ OR Fed"
    crypto_query = "æ¯”ç‰¹å¹£ OR ä»¥å¤ªåŠ OR åŠ å¯†è²¨å¹£ OR Bitcoin OR Ethereum"

    tw_posts = _dedupe(_fetch_google_news(tw_query), sent_titles)
    us_posts = _dedupe(_fetch_google_news(us_query), sent_titles)
    crypto_posts = _dedupe(_fetch_google_news(crypto_query), sent_titles)

    sections = []
    if tw_posts:
        sections.append({"name": "ğŸ¹ å°è‚¡", "content": _build_section_lines(tw_posts, MAX_ITEMS_PER_SECTION)})
    if us_posts:
        sections.append({"name": "âš¡ ç¾è‚¡", "content": _build_section_lines(us_posts, MAX_ITEMS_PER_SECTION)})
    if crypto_posts:
        sections.append({"name": "ğŸª™ Crypto", "content": _build_section_lines(crypto_posts, MAX_ITEMS_PER_SECTION)})

    if not sections:
        print("âœ… ç„¡æ–°å…§å®¹ï¼ˆå¯èƒ½éƒ½å·²æ¨æ’­éï¼‰ï¼Œè·³éã€‚")
        return

    send_to_discord(label, sections)

    # æ›´æ–°å¿«å–ï¼šæŠŠæœ¬æ¬¡æ–°æ¨æ’­çš„ title åŠ å…¥
    new_titles = [p["title"] for p in (tw_posts[:MAX_ITEMS_PER_SECTION] + us_posts[:MAX_ITEMS_PER_SECTION] + crypto_posts[:MAX_ITEMS_PER_SECTION])]
    _save_sent_titles(new_titles + sent_titles)


def _label_by_time(taipei_now: datetime.datetime) -> str:
    """
    ä¾ç…§ä½ çš„ workflow æ™‚æ®µçµ¦å›ºå®šæ¨™é¡Œï¼ˆé¡¯ç¤ºæ–¹å¼ä¿æŒä½ åŸæœ¬ã€Œæ™‚æ®µæ¨™ç±¤ã€é‚è¼¯ï¼‰ã€‚
    """
    h = taipei_now.hour
    m = taipei_now.minute

    # 08:30 å·¦å³
    if h == 8 and 0 <= m <= 59:
        return "ğŸ¹ å°è‚¡é–‹ç›¤é å ±"
    # 15:30 å·¦å³
    if h == 15 and 0 <= m <= 59:
        return "ğŸ“Š å°è‚¡ç›¤å¾Œç¸½çµ"
    # 21:30 å·¦å³
    if h == 21 and 0 <= m <= 59:
        return "âš¡ ç¾è‚¡é–‹ç›¤å‰å¤•"
    # 06:00 å·¦å³
    if h == 6 and 0 <= m <= 59:
        return "ğŸŒ™ ç¾è‚¡ç›¤å¾Œå›é¡§"

    # fallbackï¼šæ‰‹å‹•è§¸ç™¼æˆ–ä¸åœ¨æ’ç¨‹æ™‚æ®µ
    if 8 <= h < 17:
        return "ğŸ¹ å°è‚¡å¿«è¨Š"
    return "âš¡ ç¾è‚¡å¿«è¨Š"


if __name__ == "__main__":
    taipei_tz = datetime.timezone(datetime.timedelta(hours=8))
    now = datetime.datetime.now(taipei_tz)
    label = _label_by_time(now)
    run_push(label)
