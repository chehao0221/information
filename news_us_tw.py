import datetime
import os
import re
import urllib.parse
from typing import Dict, List

import feedparser
import requests


# =========================
# è¨­å®š
# =========================
DISCORD_WEBHOOK_URL = os.getenv("NEWS_WEBHOOK_URL", "").strip()
CACHE_FILE = "data/sent_news.txt"

# Google News RSS
# èªç³»ï¼šç¹ä¸­ï¼ˆå°ç£ï¼‰
GOOGLE_NEWS_RSS = "https://news.google.com/rss/search?q={query}&hl=zh-TW&gl=TW&ceid=TW:zh-Hant"

# æœ€å¤šæ¨æ’­å¹¾å‰‡ï¼ˆæ¯å€‹åˆ†é¡ï¼‰
MAX_ITEMS_PER_SECTION = 6
# å¿«å–æœ€å¤šä¿ç•™å¹¾ç­†ï¼ˆé¿å… repo è¶Šä¾†è¶Šå¤§ï¼‰
CACHE_KEEP_LIMIT = 300

# Requests timeout
HTTP_TIMEOUT = 12


def _ensure_data_dir() -> None:
    if not os.path.exists("data"):
        os.makedirs("data", exist_ok=True)


def _normalize_title(title: str) -> str:
    # ç°¡å–®æ­£è¦åŒ–ï¼šå»ç©ºç™½ã€é™å™ªç¬¦è™Ÿã€è½‰å°å¯«
    t = (title or "").strip().lower()
    t = re.sub(r"\s+", " ", t)
    return t


def _load_sent_titles() -> List[str]:
    if not os.path.exists(CACHE_FILE):
        return []
    try:
        with open(CACHE_FILE, "r", encoding="utf-8") as f:
            return [line.strip() for line in f if line.strip()]
    except Exception:
        return []


def _save_sent_titles(titles: List[str]) -> None:
    _ensure_data_dir()
    # å»é‡ + é™åˆ¶é•·åº¦
    seen = set()
    cleaned: List[str] = []
    for t in titles:
        nt = _normalize_title(t)
        if not nt or nt in seen:
            continue
        seen.add(nt)
        cleaned.append(t.strip())
    cleaned = cleaned[:CACHE_KEEP_LIMIT]
    with open(CACHE_FILE, "w", encoding="utf-8") as f:
        for t in cleaned:
            f.write(f"{t}\n")


def _fetch_google_news(query: str) -> List[Dict[str, str]]:
    q = urllib.parse.quote_plus(query)
    url = GOOGLE_NEWS_RSS.format(query=q)

    feed = feedparser.parse(url)
    posts: List[Dict[str, str]] = []
    for e in (feed.entries or []):
        title = (e.get("title") or "").strip()
        link = (e.get("link") or "").strip()
        if not title or not link:
            continue
        posts.append({"title": title, "link": link})
    return posts


def _dedupe(posts: List[Dict[str, str]], sent_titles: List[str]) -> List[Dict[str, str]]:
    sent_norm = set(_normalize_title(t) for t in sent_titles)
    out: List[Dict[str, str]] = []
    for p in posts:
        nt = _normalize_title(p.get("title", ""))
        if not nt or nt in sent_norm:
            continue
        out.append(p)
    return out


def _build_section_lines(posts: List[Dict[str, str]], limit: int) -> str:
    # Discord Embed description ä¸Šé™ 4096ï¼Œä¿å®ˆæˆªæ–·
    lines: List[str] = []
    for p in posts[:limit]:
        title = p["title"]
        link = p["link"]
        lines.append(f"â€¢ [{title}]({link})")
    text = "\n".join(lines)
    return text[:3900]  # ç•™ buffer


def send_to_discord(title: str, sections: List[Dict[str, str]]) -> None:
    """
    Send to Discord via webhook (plain content, chunked).
    This avoids Discord embed size limits (6000 per embed, 4096 description, etc).

    Display style kept: **å€å¡Šå** + å¤šè¡Œæ¢åˆ—å…§å®¹.
    """
    if not DISCORD_WEBHOOK_URL:
        print("âš ï¸ NEWS_WEBHOOK_URL æœªè¨­å®šï¼Œè·³éæ¨æ’­ã€‚")
        return

    # Build blocks: **name**\ncontent
    blocks: List[str] = []
    for s in sections:
        name = (s.get("name") or "").strip()
        content = (s.get("content") or "").strip()
        if not name and not content:
            continue
        if not content:
            content = "ï¼ˆæœ¬æ¬¡æ²’æœ‰æ–°çš„æ›´æ–°ï¼‰"
        if name:
            blocks.append(f"**{name}**\n{content}")
        else:
            blocks.append(content)

    if not blocks:
        text = f"**{(title or 'News').strip()[:256]}**\nï¼ˆæœ¬æ¬¡æ²’æœ‰æ–°çš„æ›´æ–°ï¼‰"
    else:
        header = f"**{(title or 'News').strip()[:256]}**"
        text = header + "\n\n" + "\n\n".join(blocks)

    # Discord webhook content limit: 2000 chars per message.
    # We'll chunk at newline boundaries for readability.
    max_len = 1900  # headroom for safety
    chunks: List[str] = []
    buf: List[str] = []
    buf_len = 0

    def flush():
        nonlocal buf, buf_len
        if buf:
            chunks.append("\n".join(buf).strip())
            buf = []
            buf_len = 0

    for line in text.splitlines():
        # If a single line is too long, hard-split it.
        while len(line) > max_len:
            part = line[:max_len]
            line = line[max_len:]
            if buf:
                flush()
            chunks.append(part)
        add_len = len(line) + (1 if buf else 0)
        if buf_len + add_len > max_len:
            flush()
        buf.append(line)
        buf_len += add_len

    flush()

    # Send chunks sequentially
    for i, chunk in enumerate(chunks, start=1):
        payload = {"content": chunk}
        try:
            r = requests.post(DISCORD_WEBHOOK_URL, json=payload, timeout=HTTP_TIMEOUT)
        except Exception as e:
            print(f"âŒ Discord webhook request error (chunk {i}/{len(chunks)}): {e}")
            return
        if r.status_code >= 300:
            print(f"âŒ Discord webhook failed (chunk {i}/{len(chunks)}): {r.status_code} {r.text[:500]}")
            return

    print(f"âœ… Discord sent: {len(chunks)} message(s)")

def run_push(label: str) -> None:
    """
    ä»¥ã€Œå°è‚¡ / ç¾è‚¡ / Cryptoã€ç‚ºä¸»ï¼Œæ¯æ¬¡æ¨æ’­å›ºå®šä¸‰æ®µï¼ˆå…§å®¹ä¸è¶³å°±ç•¥éï¼‰ã€‚
    """
    _ensure_data_dir()
    sent_titles = _load_sent_titles()

    # ä¸»è¦é—œéµå­—ï¼ˆä½ å¯ä»¥ä¹‹å¾Œå†è‡ªè¡Œå¾®èª¿ï¼‰
    tw_query = "å°è‚¡ OR å°ç£ è‚¡å¸‚ OR åŠ æ¬ŠæŒ‡æ•¸ OR å°æŒ‡æœŸ OR å°ç©é›»"
    us_query = "ç¾è‚¡ OR ç¾åœ‹ è‚¡å¸‚ OR é“ç“Š OR é‚£æ–¯é”å…‹ OR æ¨™æ™®500 OR è¯æº–æœƒ OR Fed"
    crypto_query = "æ¯”ç‰¹å¹£ OR ä»¥å¤ªåŠ OR åŠ å¯†è²¨å¹£ OR Bitcoin OR Ethereum"

    tw_posts = _dedupe(_fetch_google_news(tw_query), sent_titles)
    us_posts = _dedupe(_fetch_google_news(us_query), sent_titles)
    crypto_posts = _dedupe(_fetch_google_news(crypto_query), sent_titles)

    sections = []
    if tw_posts:
        sections.append({"name": "ğŸ¹ å°è‚¡", "content": _build_section_lines(tw_posts, MAX_ITEMS_PER_SECTION)})
    if us_posts:
        sections.append({"name": "âš¡ ç¾è‚¡", "content": _build_section_lines(us_posts, MAX_ITEMS_PER_SECTION)})
    if crypto_posts:
        sections.append({"name": "ğŸª™ Crypto", "content": _build_section_lines(crypto_posts, MAX_ITEMS_PER_SECTION)})

    if not sections:
        print("âœ… ç„¡æ–°å…§å®¹ï¼ˆå¯èƒ½éƒ½å·²æ¨æ’­éï¼‰ï¼Œè·³éã€‚")
        return

    send_to_discord(label, sections)

    # æ›´æ–°å¿«å–ï¼šæŠŠæœ¬æ¬¡æ–°æ¨æ’­çš„ title åŠ å…¥
    new_titles = [p["title"] for p in (tw_posts[:MAX_ITEMS_PER_SECTION] + us_posts[:MAX_ITEMS_PER_SECTION] + crypto_posts[:MAX_ITEMS_PER_SECTION])]
    _save_sent_titles(new_titles + sent_titles)


def _label_by_time(taipei_now: datetime.datetime) -> str:
    """
    ä¾ç…§ä½ çš„ workflow æ™‚æ®µçµ¦å›ºå®šæ¨™é¡Œï¼ˆé¡¯ç¤ºæ–¹å¼ä¿æŒä½ åŸæœ¬ã€Œæ™‚æ®µæ¨™ç±¤ã€é‚è¼¯ï¼‰ã€‚
    """
    h = taipei_now.hour
    m = taipei_now.minute

    # 08:30 å·¦å³
    if h == 8 and 0 <= m <= 59:
        return "ğŸ¹ å°è‚¡é–‹ç›¤é å ±"
    # 15:30 å·¦å³
    if h == 15 and 0 <= m <= 59:
        return "ğŸ“Š å°è‚¡ç›¤å¾Œç¸½çµ"
    # 21:30 å·¦å³
    if h == 21 and 0 <= m <= 59:
        return "âš¡ ç¾è‚¡é–‹ç›¤å‰å¤•"
    # 06:00 å·¦å³
    if h == 6 and 0 <= m <= 59:
        return "ğŸŒ™ ç¾è‚¡ç›¤å¾Œå›é¡§"

    # fallbackï¼šæ‰‹å‹•è§¸ç™¼æˆ–ä¸åœ¨æ’ç¨‹æ™‚æ®µ
    if 8 <= h < 17:
        return "ğŸ¹ å°è‚¡å¿«è¨Š"
    return "âš¡ ç¾è‚¡å¿«è¨Š"


if __name__ == "__main__":
    taipei_tz = datetime.timezone(datetime.timedelta(hours=8))
    now = datetime.datetime.now(taipei_tz)
    label = _label_by_time(now)
    run_push(label)
