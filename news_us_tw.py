import yfinance as yf
import requests
import datetime
import os
import feedparser
import urllib.parse

# =============================
# åŸºç¤è¨­å®š
# =============================
DISCORD_WEBHOOK_URL = os.getenv("NEWS_WEBHOOK_URL", "").strip()
CACHE_FILE = "data/sent_news.txt"
TZ_TW = datetime.timezone(datetime.timedelta(hours=8))
MAX_EMBEDS = 10
NEWS_HOURS_LIMIT = 12

# =============================
# æŒ‡æ•¸æ‘˜è¦
# =============================
def get_market_price(market_type="TW"):
    try:
        sym = "^TWII" if market_type == "TW" else "^GSPC"
        name = "åŠ æ¬ŠæŒ‡æ•¸" if market_type == "TW" else "S&P 500"

        ticker = yf.Ticker(sym)
        info = ticker.fast_info
        current = info.get("last_price")
        prev = info.get("previous_close")

        if not current or not prev:
            return "âš ï¸ æŒ‡æ•¸è³‡æ–™æš«ç¼º"

        pct = ((current - prev) / prev) * 100
        emoji = "ğŸ“ˆ" if pct >= 0 else "ğŸ“‰"
        return f"{emoji} {name}: {current:.2f} ({pct:+.2f}%)"
    except Exception:
        return "âš ï¸ æŒ‡æ•¸å–å¾—å¤±æ•—"

# =============================
# Embed å¡ç‰‡ï¼ˆä»¿ Quant Bot åœ–äºŒï¼‰
# =============================
def create_news_embed(post, market_type):
    color = 0x3498db if market_type == "TW" else 0xe74c3c

    return {
        "title": post["title"],
        "url": post["link"],
        "color": color,
        "fields": [
            {
                "name": "âš–ï¸ å¸‚å ´è¡¨ç¾",
                "value": "å¹³ç©©",
                "inline": True
            },
            {
                "name": "ğŸ•’ ç™¼å¸ƒæ™‚é–“",
                "value": f"{post['time']}ï¼ˆå°åŒ—ï¼‰",
                "inline": True
            },
            {
                "name": "ğŸ“° æ–°èä¾†æº",
                "value": post["source"],
                "inline": False
            }
        ],
        "footer": {
            "text": "Quant Bot Intelligence System"
        }
    }

# =============================
# ä¸»æµç¨‹
# =============================
def get_market_news(market_type="TW"):
    if not DISCORD_WEBHOOK_URL:
        print("âŒ æœªè¨­å®š NEWS_WEBHOOK_URL")
        return

    os.makedirs("data", exist_ok=True)

    # å·²æ¨é€æ–°èå¿«å–
    sent_titles = set()
    if os.path.exists(CACHE_FILE):
        with open(CACHE_FILE, "r", encoding="utf-8") as f:
            sent_titles = {line.strip() for line in f if line.strip()}

    # æœå°‹è¨­å®š
    if market_type == "TW":
        queries = ["å°è‚¡ è²¡ç¶“", "åŠ æ¬ŠæŒ‡æ•¸ èµ°å‹¢", "ETF é…æ¯"]
        label = "ğŸ¹ å°è‚¡å¸‚å ´å¿«è¨Š | Morning Brief"
    else:
        queries = ["ç¾è‚¡ ç›¤å‰", "è¯æº–æœƒ åˆ©ç‡", "S&P500 èµ°å‹¢"]
        label = "âš¡ ç¾è‚¡å¸‚å ´å¿«è¨Š | Market Brief"

    collected = {}
    now_utc = datetime.datetime.now(datetime.timezone.utc)

    for q in queries:
        url = (
            "https://news.google.com/rss/search?"
            f"q={urllib.parse.quote(q)}&hl=zh-TW&gl=TW&ceid=TW:zh-TW"
        )
        feed = feedparser.parse(url)

        for entry in feed.entries[:5]:
            if not hasattr(entry, "published_parsed"):
                continue

            title = entry.title.split(" - ")[0]
            source = entry.title.split(" - ")[-1] if " - " in entry.title else "è²¡ç¶“æ–°è"

            if title in sent_titles or title in collected:
                continue

            pub_utc = datetime.datetime(
                *entry.published_parsed[:6],
                tzinfo=datetime.timezone.utc
            )

            if (now_utc - pub_utc).total_seconds() / 3600 > NEWS_HOURS_LIMIT:
                continue

            pub_tw = pub_utc.astimezone(TZ_TW)

            collected[title] = {
                "title": title,
                "link": entry.link,
                "source": source,
                "time": pub_tw.strftime("%H:%M"),
                "sort_time": pub_tw
            }

    if not collected:
        print("â„¹ï¸ æ²’æœ‰æ–°æ–°è")
        return

    # ä¾æ™‚é–“æ–° â†’ èˆŠæ’åº
    posts = sorted(
        collected.values(),
        key=lambda x: x["sort_time"],
        reverse=True
    )[:MAX_EMBEDS]

    embeds = [create_news_embed(p, market_type) for p in posts]

    now_str = datetime.datetime.now(TZ_TW).strftime("%Y-%m-%d %H:%M")
    price_summary = get_market_price(market_type)

    payload = {
        "content": (
            f"## {label}\n"
            f"ğŸ“… `{now_str}`\n"
            f"ğŸ“Š **{price_summary}**\n"
            f"â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€"
        ),
        "embeds": embeds
    }

    try:
        resp = requests.post(DISCORD_WEBHOOK_URL, json=payload, timeout=15)
        if resp.status_code in (200, 204):
            sent_titles.update(p["title"] for p in posts)
            with open(CACHE_FILE, "w", encoding="utf-8") as f:
                for t in list(sent_titles)[-300:]:
                    f.write(f"{t}\n")
            print(f"âœ… æˆåŠŸæ¨é€ {len(embeds)} å‰‡æ–°è")
        else:
            print(f"âŒ Webhook å¤±æ•—ï¼š{resp.status_code}")
    except Exception as e:
        print(f"âŒ ç™¼é€éŒ¯èª¤ï¼š{e}")

# =============================
# å…¥å£
# =============================
if __name__ == "__main__":
    now = datetime.datetime.now(TZ_TW)
    market = "TW" if 6 <= now.hour < 17 else "US"
    get_market_news(market)
