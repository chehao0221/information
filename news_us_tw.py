import feedparser
import requests
import os
from datetime import datetime

# è®€å–ä¸¦è‡ªå‹•æ¸…ç†ç¶²å€å¯èƒ½çš„ç©ºç™½æˆ–æ›è¡Œ
WEBHOOK = os.environ.get("NEWS_WEBHOOK_URL", "").strip()

def get_news(query, lang='zh-TW', region='TW'):
    url = f"https://news.google.com/rss/search?q={query}&hl={lang}&gl={region}&ceid={region}:{lang}"
    feed = feedparser.parse(url)
    return [{"title": entry.title, "link": entry.link} for entry in feed.entries[:3]] if feed.entries else []

def run():
    if not WEBHOOK:
        print("âŒ éŒ¯èª¤ï¼šæ‰¾ä¸åˆ° NEWS_WEBHOOK_URLï¼Œè«‹æª¢æŸ¥ Secrets è¨­å®šã€‚")
        return

    # å®šç¾©æ¨™çš„
    targets = {
        "ğŸ“ˆ å°ç¾è‚¡ç„¦é»": "å°è‚¡ èµ°å‹¢ NVIDIA Apple",
        "ğŸ¦… ç¸½ç¶“å‹•æ…‹": "Federal Reserve Fed CPI"
    }

    now = datetime.now().strftime("%Y-%m-%d %H:%M")
    msg = f"ğŸ—ï¸ **ç›¤å‰æ¶ˆæ¯é¢å ±** ({now})\nâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n"

    for label, query in targets.items():
        news = get_news(query)
        msg += f"**ã€{label}ã€‘**\n"
        for n in news:
            msg += f"ğŸ”¹ {n['title']}\n  <{n['link']}>\n"

    msg += "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\nğŸ’¡ *AI è‡ªå‹•å½™æ•´ï¼Œåƒ…ä¾›åƒè€ƒã€‚*"

    # ç™¼é€ä¸¦å¼·åˆ¶å›å ±çµæœ
    res = requests.post(WEBHOOK, json={"content": msg})
    print(f"ğŸ“¡ ç™¼é€ç‹€æ…‹: {res.status_code}")
    if res.status_code not in [200, 204]:
        print(f"âŒ éŒ¯èª¤å…§å®¹: {res.text}")

if __name__ == "__main__":
    run()
