import yfinance as yf
import pandas as pd
import numpy as np
import requests
import datetime
import os
import feedparser
import urllib.parse
from xgboost import XGBRegressor
import warnings

warnings.filterwarnings("ignore")

# è®€å– Webhook ç¶²å€
DISCORD_WEBHOOK_URL = os.getenv("NEWS_WEBHOOK_URL", "").strip()

def get_live_news(query):
    """æŠ“å–æœ€æ–°æ–°èï¼Œä¸¦éæ¿¾æ‰è¶…é 12 å°æ™‚çš„èˆŠè"""
    try:
        safe_query = urllib.parse.quote(query)
        url = f"https://news.google.com/rss/search?q={safe_query}&hl=zh-TW&gl=TW&ceid=TW:zh-TW"
        feed = feedparser.parse(url)
        
        if feed.entries:
            entry = feed.entries[0]
            
            # --- æ™‚é–“éæ¿¾é‚è¼¯ ---
            # å°‡æ–°èç™¼å¸ƒæ™‚é–“è½‰ç‚º datetime ç‰©ä»¶ (UTC)
            pub_time = datetime.datetime(*entry.published_parsed[:6])
            now_time = datetime.datetime.utcnow()
            
            # è¨ˆç®—æ™‚å·®ï¼ˆå°æ™‚ï¼‰
            diff_hours = (now_time - pub_time).total_seconds() / 3600
            
            # å¦‚æœæ–°èè¶…é 12 å°æ™‚ï¼Œè¦–ç‚ºèˆŠèä¸é¡¯ç¤º
            if diff_hours > 12:
                print(f"è·³éèˆŠè: {entry.title} ({int(diff_hours)}å°æ™‚å‰)")
                return None
            
            clean_title = entry.title.split(" - ")[0]
            return {"title": clean_title, "link": entry.link}
        return None
    except Exception as e:
        print(f"æ–°èæŠ“å–å¤±æ•—: {e}")
        return None

def compute_features(df):
    """è¨ˆç®— AI é‡åŒ–æŒ‡æ¨™"""
    df = df.copy()
    df["mom20"] = df["Close"].pct_change(20)
    df["mom60"] = df["Close"].pct_change(60)
    delta = df["Close"].diff()
    up = delta.clip(lower=0).rolling(14).mean()
    down = (-delta.clip(upper=0)).rolling(14).mean()
    df["rsi"] = 100 - (100 / (1 + up / (down + 1e-9)))
    df["vol_ratio"] = df["Volume"] / (df["Volume"].rolling(20).mean() + 1e-9)
    df["volatility"] = df["Close"].pct_change().rolling(20).std()
    return df

def run():
    if not DISCORD_WEBHOOK_URL:
        print("âŒ éŒ¯èª¤ï¼šæ‰¾ä¸åˆ° Webhook URL")
        return

    # ç›£æ§æ¸…å–®
    must_watch = ["2330.TW", "2317.TW", "0050.TW", "AAPL", "NVDA", "TSLA"]
    tz = datetime.timezone(datetime.timedelta(hours=8))
    now_time = datetime.datetime.now(tz).strftime("%Y-%m-%d %H:%M")

    # 1. ç™¼é€ç²¾ç¾æ¨™é¡Œ
    header_msg = (
        f"ğŸ›°ï¸ **AI æŠ•è³‡æƒ…å ±ç«™ - ç›¤å‰å¿«è¨Š**\n"
        f"ğŸ“… å ±å‘Šæ™‚é–“ï¼š`{now_time}` (å°åŒ—)\n"
        f"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
    )
    requests.post(DISCORD_WEBHOOK_URL, json={"content": header_msg})

    for sym in must_watch:
        try:
            # 2. æ•¸æ“šæŠ“å–
            ticker = yf.Ticker(sym)
            df = ticker.history(period="2y", timeout=25) 
            if df.empty: continue

            # 3. AI é æ¸¬æ ¸å¿ƒ (XGBoost)
            ai_status = "ğŸ“‰ æ•¸æ“šä¸è¶³"
            pred_val = 0
            if len(df) > 60:
                try:
                    df_feat = compute_features(df)
                    df_feat["target"] = df_feat["Close"].shift(-5) / df_feat["Close"] - 1
                    features = ["mom20", "mom60", "rsi", "vol_ratio", "volatility"]
                    train_df = df_feat.dropna(subset=features + ["target"])
                    
                    model = XGBRegressor(n_estimators=50, max_depth=3, learning_rate=0.1)
                    model.fit(train_df[features], train_df["target"])
                    
                    last_features = df_feat[features].iloc[-1:].values
                    pred_val = float(model.predict(last_features)[0])
                    
                    if pred_val > 0.08: emoji = "ğŸ’¥ **æ¥µåº¦çœ‹å¤š**"
                    elif pred_val > 0.03: emoji = "ğŸ”¥ **å¼·å‹¢çœ‹å¤š**"
                    elif pred_val > 0.01: emoji = "ğŸš€ **ç©©å®šåå¤š**"
                    elif pred_val > 0: emoji = "ğŸ“ˆ **å¾®å¹…çœ‹å¤š**"
                    else: emoji = "â˜ï¸ **ä¸­æ€§è§€æœ›**"
                    
                    ai_status = f"{emoji} (`{pred_val:+.2%}`)"
                except:
                    ai_status = "âš ï¸ åˆ†æç•°å¸¸"

            # 4. æ–°èæŠ“å– (å« 12 å°æ™‚å»é‡éæ¿¾)
            news = get_live_news(sym.split('.')[0])
            curr_price = float(df['Close'].iloc[-1])

            # 5. è¨Šæ¯æ ¼å¼åŒ–
            is_hot = "â­ï¸" if pred_val > 0.05 else ""
            
            report = (
                f"{is_hot} **æ¨™çš„ï¼š{sym}** {is_hot}\n"
                f"ğŸ’° ç¾åƒ¹ï¼š`{curr_price:.2f}`\n"
                f"ğŸ¤– AI é ä¼°ï¼š{ai_status}\n"
            )
            
            if news:
                report += f"ğŸ“° é ­æ¢ï¼š{news['title']}\nğŸ”— <{news['link']}>\n"
            else:
                report += f"â„¹ï¸ è¿‘ 12 å°æ™‚ç„¡é‡å¤§ç›¸é—œæ–°è\n"
            
            requests.post(DISCORD_WEBHOOK_URL, json={"content": report})
            print(f"âœ… {sym} è™•ç†å®Œæˆ")

        except Exception as e:
            print(f"âŒ {sym} éŒ¯èª¤: {e}")

    # çµå°¾è²æ˜
    footer = (
        f"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n"
        f"ğŸ“Œ *å°å¸³æç¤ºï¼šæœ¬é æ¸¬ç‚º 5 å€‹äº¤æ˜“æ—¥ç›®æ¨™ï¼Œè«‹æ–¼ä¸€é€±å¾Œå›æ¸¬ã€‚*\n"
        f"âš ï¸ *æŠ•è³‡ç›ˆè™§è‡ªè² ï¼ŒAI åƒ…ä¾›ç­–ç•¥åƒè€ƒã€‚*"
    )
    requests.post(DISCORD_WEBHOOK_URL, json={"content": footer})

if __name__ == "__main__":
    run()
