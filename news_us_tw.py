import yfinance as yf
import requests
import datetime
import os
import feedparser
import urllib.parse

# åŸºç¤è¨­å®š
DISCORD_WEBHOOK_URL = os.getenv("NEWS_WEBHOOK_URL", "").strip()
CACHE_FILE = "data/sent_news.txt"

def get_market_price(market_type="TW"):
    """ç²å–ä¸»è¦æŒ‡æ•¸çš„å³æ™‚è¡Œæƒ…æ‘˜è¦"""
    try:
        if market_type == "TW":
            # å°æŒ‡æœŸè¿‘æœˆã€åŠ æ¬ŠæŒ‡æ•¸
            symbols = {"å°æŒ‡æœŸè²¨": "WTX&=F", "åŠ æ¬ŠæŒ‡æ•¸": "^TWII"}
        else:
            # å°é“ç“ŠæœŸè²¨ã€æ¨™æ™®500æœŸè²¨ã€é‚£æ–¯é”å…‹æœŸè²¨
            symbols = {"é“ç“ŠæœŸè²¨": "YM=F", "S&P500æœŸè²¨": "ES=F", "é‚£æŒ‡æœŸè²¨": "NQ=F"}
        
        price_text = "ğŸ“Š **ç•¶å‰è¡Œæƒ…æ‘˜è¦ï¼š**\n"
        for name, sym in symbols.items():
            ticker = yf.Ticker(sym)
            data = ticker.fast_info
            current = data.last_price
            change = current - data.previous_close
            pct_change = (change / data.previous_close) * 100
            emoji = "ğŸ”´" if change < 0 else "ğŸŸ¢"
            price_text += f"{emoji} {name}: {current:.2f} ({change:+.2f} / {pct_change:+.2f}%)\n"
        return price_text
    except Exception as e:
        return f"âš ï¸ ç„¡æ³•å–å¾—å³æ™‚å ±åƒ¹: {e}"

def send_to_discord(label, posts, price_summary=""):
    """å°‡æ–°èèˆ‡è¡Œæƒ…ç™¼é€åˆ° Discord"""
    if not DISCORD_WEBHOOK_URL or not posts: return
    
    embeds = []
    for post in posts:
        color = 3066993 if "å°è‚¡" in label else 15258703
        embeds.append({
            "title": post["title"],
            "url": post["link"],
            "description": f"â° æ™‚é–“: {post['time']} (å°åŒ—)",
            "color": color
        })

    # åˆ†æ‰¹ç™¼é€ï¼Œè¡Œæƒ…æ‘˜è¦æ”¾åœ¨é¦–å‰‡è¨Šæ¯
    for i in range(0, len(embeds), 10):
        payload = {
            "content": f"## {label}\n{price_summary if i == 0 else ''}",
            "embeds": embeds[i:i+10]
        }
        requests.post(DISCORD_WEBHOOK_URL, json=payload)

def get_market_news(market_type="TW"):
    """æŠ“å–æ–°èä¸¦éæ¿¾é‡è¤‡"""
    if not os.path.exists("data"): os.makedirs("data")
    
    sent_titles = set()
    if os.path.exists(CACHE_FILE):
        with open(CACHE_FILE, "r", encoding="utf-8") as f:
            sent_titles = {line.strip() for line in f.readlines()}

    price_summary = get_market_price(market_type)
    
    if market_type == "TW":
        queries = ["å°è‚¡ è²¡ç¶“", "åŠ æ¬ŠæŒ‡æ•¸ èµ°å‹¢"]
        label = "ğŸ¹ å°è‚¡å¸‚å ´æ¦‚æ³"
    else:
        queries = ["ç¾è‚¡ ç›¤å‰", "è¯æº–æœƒ åˆ©ç‡", "S&P500 èµ°å‹¢"]
        label = "âš¡ ç¾è‚¡å³æ™‚æƒ…å ±"

    new_posts = []
    current_session_titles = []

    for q in queries:
        url = f"https://news.google.com/rss/search?q={urllib.parse.quote(q)}&hl=zh-TW&gl=TW&ceid=TW:zh-TW"
        feed = feedparser.parse(url)
        for entry in feed.entries[:5]:
            title = entry.title.split(" - ")[0]
            if title in sent_titles: continue
            
            pub_time = datetime.datetime(*entry.published_parsed[:6])
            if (datetime.datetime.utcnow() - pub_time).total_seconds() / 3600 < 12:
                new_posts.append({
                    "title": title,
                    "link": entry.link,
                    "time": (pub_time + datetime.timedelta(hours=8)).strftime("%H:%M")
                })
                sent_titles.add(title)
                current_session_titles.append(title)

    if new_posts:
        send_to_discord(label, new_posts, price_summary)
        # æ›´æ–°å¿«å–ï¼Œä¿ç•™æœ€æ–° 150 ç­†
        all_titles = list(sent_titles)[-150:]
        with open(CACHE_FILE, "w", encoding="utf-8") as f:
            for t in all_titles: f.write(f"{t}\n")

if __name__ == "__main__":
    tz_tw = datetime.timezone(datetime.timedelta(hours=8))
    now = datetime.datetime.now(tz_tw)
    
    if 6 <= now.hour < 17:
        get_market_news("TW")
    else:
        get_market_news("US")
